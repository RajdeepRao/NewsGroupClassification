# NewsGroupClassification

README

As a part of this project, two text categorization classifiers: one using naive Bayes and the other using decision trees was developed. The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of my knowledge, it was originally collected by Ken Lang, probably for his Newsweeder: Learning to filter netnews paper, though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering The data is represented in a bag-of-words format, where each post is represented by what words are present in it, without any consideration of the order of the words. I have used a binary representation of the word counts (essentially nothing but a sparse matrix) for the computation.

I have also implemented the Logistic regression for classification, but that is done via a separate script which you'll find in the same script, for a subset data set that is a smaller version of the already existing 20 newsgroup dataset.

I've used Anaconda with Spyder as my IDE and IPython as my console on a Windows 10 Environment
I've used the SciKit, SciLearn, numPy, Pandas etc for libraries. They were pre-installed when I downloaded it from the anaconda web site for Python 3.5. 
